



































































 99%|███████████████████████████████████████▌| 262/265 [02:15<00:01,  1.90it/s]
100%|████████████████████████████████████████| 265/265 [02:16<00:00,  2.25it/s]***** Running Evaluation *****
  Num examples = 705
  Batch size = 8

  File "2test.py", line 72, in <module>        | 14/89 [00:03<00:24,  3.06it/s]
    output = trainer.train()
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 1455, in train
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 1565, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 2208, in evaluate
    output = eval_loop(
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer.py", line 2394, in evaluation_loop
    preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer_pt_utils.py", line 108, in nested_concat
    return torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)
  File "/opt/conda/lib/python3.8/site-packages/transformers/trainer_pt_utils.py", line 70, in torch_pad_and_concatenate
    return torch.cat((tensor1, tensor2), dim=0)
RuntimeError: CUDA out of memory. Tried to allocate 4.95 GiB (GPU 0; 14.76 GiB total capacity; 6.83 GiB already allocated; 4.54 GiB free; 8.80 GiB reserved in total by PyTorch)